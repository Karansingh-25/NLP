{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4916e60e-51f7-40d3-9b6f-9e0147f6a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90f95e6-3b36-4533-bf03-13aa81929bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7afa4c18-3455-4174-8222-f611a634440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cca88cd-af64-4190-a951-542dcaecf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17c214a-239d-4e19-b3fe-c5631c78565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea608775-19bb-4495-87ca-cdb3702435d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"\n",
    "The core concept of agentic AI is the use of AI agents to perform automated tasks but without human intervention.[1] While robotic process automation (RPA) and AI agents can be programmed to automate specific tasks or support rule-based decisions, the rules are usually fixed.[2] Agentic AI operates independently, making decisions through continuous learning and analysis of external data and complex data sets.[3] Functioning agents can require various AI techniques, such as natural language processing, machine learning (ML), and computer vision, depending on the environment.[1]\n",
    "\n",
    "Particularly, reinforcement learning (RL) is essential in assisting agentic AI in making self-directed choices by supporting agents in learning best actions through the trial-and-error method. Agents using RL continuously to explore their surroundings will be given rewards or punishment for their actions, which refines their decision-making capability over time. All the while deep learning, as opposed to rule-based methods, supports agentic AI through multi-layered neural networks to learn features from extensive and complex sets of data. RL combined with deep learning thus supports the use of AI agents to adjust dynamically, optimize procedures, and engage in complex behaviors with limited control from humans.[citation needed]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa64d1c2-1ff6-4b72-a420-4c9ba63e11a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4d4f8cf-44dd-4555-aebc-2bf1e104578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b4fcf13-f030-40a3-a486-a0b37a2d5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30eac500-af65-4f35-9d3d-2b53fcc9a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55af63dd-c3ac-4639-85e9-58e22302510f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' the core concept of agentic ai is the use of ai agents to perform automated tasks but without human intervention ',\n",
       " '    while robotic process automation  rpa  and ai agents can be programmed to automate specific tasks or support rule based decisions  the rules are usually fixed ',\n",
       " '    agentic ai operates independently  making decisions through continuous learning and analysis of external data and complex data sets ',\n",
       " '    functioning agents can require various ai techniques  such as natural language processing  machine learning  ml   and computer vision  depending on the environment ',\n",
       " '     particularly  reinforcement learning  rl  is essential in assisting agentic ai in making self directed choices by supporting agents in learning best actions through the trial and error method ',\n",
       " 'agents using rl continuously to explore their surroundings will be given rewards or punishment for their actions  which refines their decision making capability over time ',\n",
       " 'all the while deep learning  as opposed to rule based methods  supports agentic ai through multi layered neural networks to learn features from extensive and complex sets of data ',\n",
       " 'rl combined with deep learning thus supports the use of ai agents to adjust dynamically  optimize procedures  and engage in complex behaviors with limited control from humans ',\n",
       " ' citation needed ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "477b2c03-e8b6-4800-b9b9-2e0f50e3ce98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentences\u001b[38;5;241m=\u001b[39mnltk\u001b[38;5;241m.\u001b[39mword_tokenize(corpus)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences_from_text(text, realign_boundaries))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1328\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1460\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1431\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mslice\u001b[39m]:\n\u001b[0;32m   1430\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1431\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m   1432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1433\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m previous_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1394\u001b[0m previous_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang_vars\u001b[38;5;241m.\u001b[39mperiod_context_re()\u001b[38;5;241m.\u001b[39mfinditer(text):\n\u001b[0;32m   1396\u001b[0m \n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# Get the slice of the previous word\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     before_text \u001b[38;5;241m=\u001b[39m text[previous_slice\u001b[38;5;241m.\u001b[39mstop : match\u001b[38;5;241m.\u001b[39mstart()]\n\u001b[0;32m   1399\u001b[0m     index_after_last_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_last_whitespace_index(before_text)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "sentences=nltk.word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbe407b9-5dab-464c-b4ea-cf9d6a924310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['core', 'concept', 'agentic', 'ai', 'use', 'ai', 'agent', 'perform', 'automated', 'task', 'without', 'human', 'intervention']\n",
      "['robotic', 'process', 'automation', 'rpa', 'ai', 'agent', 'programmed', 'automate', 'specific', 'task', 'support', 'rule', 'based', 'decision', 'rule', 'usually', 'fixed']\n",
      "['agentic', 'ai', 'operates', 'independently', 'making', 'decision', 'continuous', 'learning', 'analysis', 'external', 'data', 'complex', 'data', 'set']\n",
      "['functioning', 'agent', 'require', 'various', 'ai', 'technique', 'natural', 'language', 'processing', 'machine', 'learning', 'ml', 'computer', 'vision', 'depending', 'environment']\n",
      "['particularly', 'reinforcement', 'learning', 'rl', 'essential', 'assisting', 'agentic', 'ai', 'making', 'self', 'directed', 'choice', 'supporting', 'agent', 'learning', 'best', 'action', 'trial', 'error', 'method']\n",
      "['agent', 'using', 'rl', 'continuously', 'explore', 'surroundings', 'given', 'reward', 'punishment', 'action', 'refines', 'decision', 'making', 'capability', 'time']\n",
      "['deep', 'learning', 'opposed', 'rule', 'based', 'method', 'support', 'agentic', 'ai', 'multi', 'layered', 'neural', 'network', 'learn', 'feature', 'extensive', 'complex', 'set', 'data']\n",
      "['rl', 'combined', 'deep', 'learning', 'thus', 'support', 'use', 'ai', 'agent', 'adjust', 'dynamically', 'optimize', 'procedure', 'engage', 'complex', 'behavior', 'limited', 'control', 'human']\n",
      "['citation', 'needed']\n"
     ]
    }
   ],
   "source": [
    "for i in corpus:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]        \n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7779fc9f-efa0-47a4-927b-75635a729551",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i])  # ^ keeps the words and removes the special characters\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review=\" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14a6a1a6-44ec-437e-bb62-357163909868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['core concept agentic ai use ai agent perform automated task without human intervention',\n",
       " 'robotic process automation rpa ai agent programmed automate specific task support rule based decision rule usually fixed',\n",
       " 'agentic ai operates independently making decision continuous learning analysis external data complex data set',\n",
       " 'functioning agent require various ai technique natural language processing machine learning ml computer vision depending environment',\n",
       " 'particularly reinforcement learning rl essential assisting agentic ai making self directed choice supporting agent learning best action trial error method',\n",
       " 'agent using rl continuously explore surroundings given reward punishment action refines decision making capability time',\n",
       " 'deep learning opposed rule based method support agentic ai multi layered neural network learn feature extensive complex set data',\n",
       " 'rl combined deep learning thus support use ai agent adjust dynamically optimize procedure engage complex behavior limited control human',\n",
       " 'citation needed']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d660a-ad38-44ab-a0ea-884e85127fbc",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aecafdf7-de74-48f4-8b77-7b91713ed5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(binary=True,ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19a1490c-9d5e-4702-b4e4-5b72987d1d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d75071d-7dc1-41e4-99e5-c159f8dc45ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'core concept': 76,\n",
       " 'concept agentic': 69,\n",
       " 'agentic ai': 18,\n",
       " 'ai use': 35,\n",
       " 'use ai': 223,\n",
       " 'ai agent': 23,\n",
       " 'agent perform': 10,\n",
       " 'perform automated': 163,\n",
       " 'automated task': 43,\n",
       " 'task without': 215,\n",
       " 'without human': 232,\n",
       " 'human intervention': 112,\n",
       " 'core concept agentic': 77,\n",
       " 'concept agentic ai': 70,\n",
       " 'agentic ai use': 22,\n",
       " 'ai use ai': 36,\n",
       " 'use ai agent': 224,\n",
       " 'ai agent perform': 25,\n",
       " 'agent perform automated': 11,\n",
       " 'perform automated task': 164,\n",
       " 'automated task without': 44,\n",
       " 'task without human': 216,\n",
       " 'without human intervention': 233,\n",
       " 'robotic process': 189,\n",
       " 'process automation': 167,\n",
       " 'automation rpa': 45,\n",
       " 'rpa ai': 191,\n",
       " 'agent programmed': 12,\n",
       " 'programmed automate': 171,\n",
       " 'automate specific': 41,\n",
       " 'specific task': 201,\n",
       " 'task support': 213,\n",
       " 'support rule': 205,\n",
       " 'rule based': 193,\n",
       " 'based decision': 47,\n",
       " 'decision rule': 85,\n",
       " 'rule usually': 196,\n",
       " 'usually fixed': 227,\n",
       " 'robotic process automation': 190,\n",
       " 'process automation rpa': 168,\n",
       " 'automation rpa ai': 46,\n",
       " 'rpa ai agent': 192,\n",
       " 'ai agent programmed': 26,\n",
       " 'agent programmed automate': 13,\n",
       " 'programmed automate specific': 172,\n",
       " 'automate specific task': 42,\n",
       " 'specific task support': 202,\n",
       " 'task support rule': 214,\n",
       " 'support rule based': 206,\n",
       " 'rule based decision': 194,\n",
       " 'based decision rule': 48,\n",
       " 'decision rule usually': 86,\n",
       " 'rule usually fixed': 197,\n",
       " 'ai operates': 31,\n",
       " 'operates independently': 155,\n",
       " 'independently making': 113,\n",
       " 'making decision': 139,\n",
       " 'decision continuous': 81,\n",
       " 'continuous learning': 71,\n",
       " 'learning analysis': 121,\n",
       " 'analysis external': 37,\n",
       " 'external data': 104,\n",
       " 'data complex': 78,\n",
       " 'complex data': 63,\n",
       " 'data set': 80,\n",
       " 'agentic ai operates': 21,\n",
       " 'ai operates independently': 32,\n",
       " 'operates independently making': 156,\n",
       " 'independently making decision': 114,\n",
       " 'making decision continuous': 140,\n",
       " 'decision continuous learning': 82,\n",
       " 'continuous learning analysis': 72,\n",
       " 'learning analysis external': 122,\n",
       " 'analysis external data': 38,\n",
       " 'external data complex': 105,\n",
       " 'data complex data': 79,\n",
       " 'complex data set': 64,\n",
       " 'functioning agent': 108,\n",
       " 'agent require': 14,\n",
       " 'require various': 179,\n",
       " 'various ai': 228,\n",
       " 'ai technique': 33,\n",
       " 'technique natural': 217,\n",
       " 'natural language': 149,\n",
       " 'language processing': 115,\n",
       " 'processing machine': 169,\n",
       " 'machine learning': 135,\n",
       " 'learning ml': 125,\n",
       " 'ml computer': 145,\n",
       " 'computer vision': 67,\n",
       " 'vision depending': 230,\n",
       " 'depending environment': 90,\n",
       " 'functioning agent require': 109,\n",
       " 'agent require various': 15,\n",
       " 'require various ai': 180,\n",
       " 'various ai technique': 229,\n",
       " 'ai technique natural': 34,\n",
       " 'technique natural language': 218,\n",
       " 'natural language processing': 150,\n",
       " 'language processing machine': 116,\n",
       " 'processing machine learning': 170,\n",
       " 'machine learning ml': 136,\n",
       " 'learning ml computer': 126,\n",
       " 'ml computer vision': 146,\n",
       " 'computer vision depending': 68,\n",
       " 'vision depending environment': 231,\n",
       " 'particularly reinforcement': 161,\n",
       " 'reinforcement learning': 177,\n",
       " 'learning rl': 129,\n",
       " 'rl essential': 187,\n",
       " 'essential assisting': 98,\n",
       " 'assisting agentic': 39,\n",
       " 'ai making': 27,\n",
       " 'making self': 141,\n",
       " 'self directed': 198,\n",
       " 'directed choice': 91,\n",
       " 'choice supporting': 56,\n",
       " 'supporting agent': 209,\n",
       " 'agent learning': 8,\n",
       " 'learning best': 123,\n",
       " 'best action': 53,\n",
       " 'action trial': 2,\n",
       " 'trial error': 221,\n",
       " 'error method': 97,\n",
       " 'particularly reinforcement learning': 162,\n",
       " 'reinforcement learning rl': 178,\n",
       " 'learning rl essential': 130,\n",
       " 'rl essential assisting': 188,\n",
       " 'essential assisting agentic': 99,\n",
       " 'assisting agentic ai': 40,\n",
       " 'agentic ai making': 19,\n",
       " 'ai making self': 28,\n",
       " 'making self directed': 142,\n",
       " 'self directed choice': 199,\n",
       " 'directed choice supporting': 92,\n",
       " 'choice supporting agent': 57,\n",
       " 'supporting agent learning': 210,\n",
       " 'agent learning best': 9,\n",
       " 'learning best action': 124,\n",
       " 'best action trial': 54,\n",
       " 'action trial error': 3,\n",
       " 'trial error method': 222,\n",
       " 'agent using': 16,\n",
       " 'using rl': 225,\n",
       " 'rl continuously': 185,\n",
       " 'continuously explore': 73,\n",
       " 'explore surroundings': 100,\n",
       " 'surroundings given': 211,\n",
       " 'given reward': 110,\n",
       " 'reward punishment': 181,\n",
       " 'punishment action': 173,\n",
       " 'action refines': 0,\n",
       " 'refines decision': 175,\n",
       " 'decision making': 83,\n",
       " 'making capability': 137,\n",
       " 'capability time': 55,\n",
       " 'agent using rl': 17,\n",
       " 'using rl continuously': 226,\n",
       " 'rl continuously explore': 186,\n",
       " 'continuously explore surroundings': 74,\n",
       " 'explore surroundings given': 101,\n",
       " 'surroundings given reward': 212,\n",
       " 'given reward punishment': 111,\n",
       " 'reward punishment action': 182,\n",
       " 'punishment action refines': 174,\n",
       " 'action refines decision': 1,\n",
       " 'refines decision making': 176,\n",
       " 'decision making capability': 84,\n",
       " 'making capability time': 138,\n",
       " 'deep learning': 87,\n",
       " 'learning opposed': 127,\n",
       " 'opposed rule': 157,\n",
       " 'based method': 49,\n",
       " 'method support': 143,\n",
       " 'support agentic': 203,\n",
       " 'ai multi': 29,\n",
       " 'multi layered': 147,\n",
       " 'layered neural': 117,\n",
       " 'neural network': 153,\n",
       " 'network learn': 151,\n",
       " 'learn feature': 119,\n",
       " 'feature extensive': 106,\n",
       " 'extensive complex': 102,\n",
       " 'complex set': 65,\n",
       " 'set data': 200,\n",
       " 'deep learning opposed': 88,\n",
       " 'learning opposed rule': 128,\n",
       " 'opposed rule based': 158,\n",
       " 'rule based method': 195,\n",
       " 'based method support': 50,\n",
       " 'method support agentic': 144,\n",
       " 'support agentic ai': 204,\n",
       " 'agentic ai multi': 20,\n",
       " 'ai multi layered': 30,\n",
       " 'multi layered neural': 148,\n",
       " 'layered neural network': 118,\n",
       " 'neural network learn': 154,\n",
       " 'network learn feature': 152,\n",
       " 'learn feature extensive': 120,\n",
       " 'feature extensive complex': 107,\n",
       " 'extensive complex set': 103,\n",
       " 'complex set data': 66,\n",
       " 'rl combined': 183,\n",
       " 'combined deep': 59,\n",
       " 'learning thus': 131,\n",
       " 'thus support': 219,\n",
       " 'support use': 207,\n",
       " 'agent adjust': 6,\n",
       " 'adjust dynamically': 4,\n",
       " 'dynamically optimize': 93,\n",
       " 'optimize procedure': 159,\n",
       " 'procedure engage': 165,\n",
       " 'engage complex': 95,\n",
       " 'complex behavior': 61,\n",
       " 'behavior limited': 51,\n",
       " 'limited control': 133,\n",
       " 'control human': 75,\n",
       " 'rl combined deep': 184,\n",
       " 'combined deep learning': 60,\n",
       " 'deep learning thus': 89,\n",
       " 'learning thus support': 132,\n",
       " 'thus support use': 220,\n",
       " 'support use ai': 208,\n",
       " 'ai agent adjust': 24,\n",
       " 'agent adjust dynamically': 7,\n",
       " 'adjust dynamically optimize': 5,\n",
       " 'dynamically optimize procedure': 94,\n",
       " 'optimize procedure engage': 160,\n",
       " 'procedure engage complex': 166,\n",
       " 'engage complex behavior': 96,\n",
       " 'complex behavior limited': 62,\n",
       " 'behavior limited control': 52,\n",
       " 'limited control human': 134,\n",
       " 'citation needed': 58}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_   #gives the index instead of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b49d995-0bc9-4bbf-88c2-dc67fe539993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d9e3b8-7b08-41d0-8387-f026a4dd0f50",
   "metadata": {},
   "source": [
    "# TF-IDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3eb01102-6998-449d-aa1c-503d01e02d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6ec8729-4671-4322-9308-8fd5eec20a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf=TfidfVectorizer(ngram_range=(2, 2),max_features=534)\n",
    "X=tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e76bd6b-14fd-4d99-a1f0-53b3330cdf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30608551, 0.        , 0.        , 0.        , 0.19860515,\n",
       "        0.22477976, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30608551, 0.        , 0.        , 0.        , 0.30608551,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30608551, 0.        ,\n",
       "        0.        , 0.        , 0.30608551, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30608551, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30608551, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30608551, 0.        ,\n",
       "        0.        , 0.        , 0.25852469, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30608551]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbaa2c1-3248-4132-b8d0-99f9edf715ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
